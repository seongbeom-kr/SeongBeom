#deep_learning #RNN 
> 모든 종류의 신호를 하나의 네트워크에서 처리하는 생체 신경망과 달리 인공신경망은 데이터 구조에 따라 각기 다른 신경망으로 처리한다. 데이터에 특별한 구조가 없다면 순방향 신경망으로 처리하지만, 2D, 3D 공간 데이터를 다룰 때는 공간상에 존재하는 특징과 형체를 포착하기 위해서는 컨볼루션 신경망을 사용한다.
> 
> 이번에는 시간적 공간적 순서 관계가 있는 순차데이터를 다룬다. 순차데이터를 다루기 위해 순방향 신경망이 어떤 구조를 갖는지, 이런 구조로 인해 발생하는 문제점은 무엇인지, 그리고 이 문제를 해결하기 위해 어떤 방향으로 발전되고 있는지 살펴본다.


# 1. 기억을 갖는 신경망 모델 RNN

__순차 데이터__ : 시간적 공간적 순서 관계가 있는 데이터

순차데이터는 시공간의 순서 관계로 형성되는 _문맥_ 또는 _콘텍스트(context)_ 를 갖는다.

현재 데이터를 이해할 때 앞 뒤에 있는 데이터를 함께 살펴보면서 콘텍스트를 파악해야 현재 데이터의 역할을 이해할 수 있다.

`나는 사과를 갖고 싶다.`  이 문장을 예시로는 사과까지만 나타냈을 때는 먹는 사과인지 용서를 구하는 사과인지 알 수 없다. 그렇기 때문에 앞 뒤 주변 단어들을 살펴봐야 판단할 수 있다.

만약 여기서 위 문장을 순방향 신경망에 입력한다면 어떻게 될까?

순방향 신경망은 입력데이터의 크기가 고정되어있고, 한 번에 입력되는 단어의 순서 정보만 알 기 때문에, _입력 데이터의 크기를 넘어서는 문장_ 을 처리하기에는 __부적절__ 하다.

이러한 문제점을 해결하기 위해 처음 등장한 네트워크는 홉필드 네트워크이다.

## 1.1 연상 기억을 하는 홉필드 네트워크
홉필드 네트워크는 새로운 입력이 들어오면 특정 패턴으로 수렴하게 만들어 기억해둔 패턴을 연상하는 네트워크이다.

이때 양극화 기법을 사용하는데, 양극화는 값이 1에 조금이라도 가까우면 1이되고, -1에 조금이라도 가까우면 -이 되게 만들어준다.

연상하려는 패턴을 1과 -1로 된 벡터로 정의하고, 입력데이터가 특정패턴으로 양극화되도록 사전에 가중치 편향을 계산해둔다.

기억해둔 패턴을 연상하기 위해 입력데이터가 양극화될 때까지 출력을 입력으로 피드백하여 연산을 반복하다가, 같아지면 연산을 멈춘다.

## 1.2 기억을 전달하는 순환신경망
인공신경망이 데이터의 순서를 고려하는 콘텍스트를 만들려면 데이터의 순차구조를 인식할 수 있어야 하고, 데이터의 콘텍스트 범위가 넓더라도 처리할 수 있어야 한다. 이러한 점들을 고려하여 만든 인공신경망이 _순환신경망(Recurrent neural network)_ 이다.

### 순차구조를 인식하며 콘텍스트를 기억하는 모델구조
순방향 신경망이나 컨볼루션 신경망과는 달리 순환신경망은 데이터의 순차구조를 인식하기 위해 데이터를 시간 순서대로 하나씩 입력 받는다. 그리고 순서대로 입력받은 데이터의 콘텍스트를 만들기 위해 은닉 계층에 피드백을 연결을 가진다.


![](https://i.imgur.com/f5lnuUI.png)[왼쪽 : 은닉계층에 피드백 연결을 갖는 모델 구조, 오른쪽은 모델이 데이터를 처리하는 과정을 시간 순서에 따라 보여준다.]

기본적으로 모델은 입력계층, 은닉 계층, 출력 계층으로 이루어지며 은닉계층은 여러 계층이 될 수 있다. 하지만 일반적으로 순환신경망은 은닉계층을 깊게 쌓아도 성능이 크게 향상이 되지 않는 경우가 많기 때문에 보통 한 두 게층 이내로 쌓는다. 

각 시간단계에서 데이터가 처리되는 과정은 순방향 신경망과 동일하게 입력 계층, 은닉계층, 출력계층 순서대로 실행된다. 다만  한가지 차이점은 은닉계층에 피드백연결이 있기 때문에 은닉상태가 다음 단계로 전달된다는 점이다.

> 여기서 말하는 은닉상태는 은닉 계층의 출력을 말한다.

은닉상태는 _"시간 단계별로 입력된 데이터가 순차적으로 추상화되어 형성된 콘텍스트"_ 를 저장한다. 그리고 피드백 연결은 _시간의 흐름에 따라 콘텍스트를 기억하는 과정_ 으로 생각할 수 있다.

### 순환 연산 방식
순환 연산을 더 자세히 살펴보면,

초기 은닉상태 $h_0$은 영벡터라고 가정하고, 각 단계를 변수 $t (t >=1)$ 로 표현하면 다음과 같은 수서로 실행된다.
- 입력계층은 새로운 입력 데이터 $x_t$를 입력받는다.
- 은닉계층은 다음 순서로 실행된다.
	- 이전 상태 $h_{t-1}$와 입력데이터 $x_t$를 합쳐 $(h_{t-1}, x_t)$로 입력받는다.
	- 함수 $f_W(h_{t-1}, x_t)$를 실행해서 은닉상태 $h_t$를 출력한다.
	- 함수 $f_W$는 순환신경망의 종류에 따라 달라지며 W는 은닉계층의 가중칠르 나타낸다.
	- 은닉상태 $h_t$는 출력계층과 다음단계의 은닉계층에 전달된다.
- 출력계층은 은닉 상태 $h_t$를 입력받아서 뉴런 연산후 $y_t$를 출력한다.

### 기본 순환 신경망 모델
이때 함수 $f_W$가 다음과 같은 형태로 정의되는 신경망을 _기본 순환 신경망(Vanilla RNN)_ 이라 한다.

$$\
\begin{align*}
y_t &\quad = tanh(W_{hh}h_{t-1} + W_{xh}x_t) \\
&\quad = tanh(W_{hh}W_{xh}({h_{t-1}x_t })^T)\\

\end{align*} \ $$

기본 순환 신경망 모델에는 다음 그림과 같이 세 종류의 가중치 $W_{xh},W_{hh},W_{hy}$가 있다. $W_{xh}$는 입력계층과 은닉계층을 연결하는 가중치이고, 가중치 $W_{hh}$는 은닉 계층의 피드백에 대한 가중치이며 가중치 $W_{hy}$는 은닉계층과 출력계층을 연결하는 가중치다. 

순환 신경망의 가중치는 모든 시간 단계에서 공유된다.


![](https://i.imgur.com/QEMnuGv.png)

기본순환 신경망의 은닉계층은 입력 $h_{t-1}, x_t$와 가중치 $W= (W_{hh}, W_{xh})$를 가중합산한 뒤에 하이퍼볼릭 탄젠트를 실행한다.

## 1.3 순환신경망의 입력, 은닉 상태, 출력
각 층들이 무엇을 표현하는지에 대한 수식 확인

### 순환신경망의 입력 $(h_{t-1}, x_t)$와 은닉상태 $h_{t}$는 무엇을 표현할까?
$$\
\begin{align*}
h_1 = f_W(h_0, x_1)\\
h_2 = f_W(h_1, x_2)\\
h_3 = f_W(h_2, x_3)\\
\cdots \\
h_4 =f_W(h_3, x_4)\\
\end{align*} \ 
$$

$h_0, x_1$은 $x_1$이므로 은닉상태  $h_1$은  $(x_1)$이 추상화된 콘텍스트를 나타내고, $(h_1, x_2 )$는 ($x_1$의 콘텍스트, $x_2$)이므로 은닉상태 $h_2$는 ($x_1, x_2$)가 추상화된 콘텍스트를 형성한다 이후 t에 도입하면 일반화식이 완성된다.

### 순환신경망은 데이터의 순차 구조를 어떻게 포착할까?
은닉 계층은 '이전 상태, 새로운 입력'을 받아서 현재 상태를 매핑하는 함수이다.

$$h_t = f_W(f_{t-1}, x_t)$$



이 식은 점화식 형태로 h0까지 전개하면 다음과 같다.

![](https://i.imgur.com/KyrxGtK.png)

즉 은닉계층을 나타내는 함수 $f_W$는 `추상화된 순차구조를 한단계 확장된 추상화된 순차구조로 매핑하는 함수`이다.

### 순환신경망의 출력 $y_t$는 무엇으로 표현할까?
첫번째 단계의 출력은 입력 x_1이 주어졌을 때 y_1의 조건부 확률 $p(y_1|x_1)$으로 표현한다. 두번째 출력은 x_1이 h_1을 통해 h_2로 전달되었으므로 입력 x_1과 x_2가 주어졌을 때 y_2의 조건부 확률 p(y_2|x_1, x_2)를 표현한다.

이렇게 표현한식을 일반화 하여 t로 바꾼 다음, 다음과 같이 근사할 수 있다.
$$p()$$