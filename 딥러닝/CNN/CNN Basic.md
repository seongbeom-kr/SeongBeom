#deep_learning #CNN #basic
*0513일 딥러닝(오민식교수님)수업과 딥러닝 교과서를 참고함*
> 강의 내용은 천천히 업데이트

순방향신경망은 데이터에 특별한 구조를 가정하지 않으므로 이미지와 같은 공간 데이터를 처리 한다면 공간적인 특성을 무시하게된다. 또한 고차원 공간을 표현하려면 데이터는 커질 수 밖에 없고, 모델도 같이 커지기 때문에 모델의 파라미터 수가 급격히 증가하는 문제가 있다. 이와 같은 순방향 신경망의 한계를 극복하기 위해 네오코그니트론이 제안되었고, 이후 CNN이 나오면서 지금까지 컴퓨터 비전 분야의 발전을 견인해오고 있다. 

이번챕터는 CNN이 이미지 처리를 위해 생체신경망의 어떤 점을 모방했고 어떤방식으로 데이터를 처리하는지,   그리고 모델이 갖는 성질이 무엇인지 확인하면서, 표준 Convolution 연산의 한계를 극복하고자 제안된  다양한 방법들을 살펴본다

# 1. 시각패턴인식을 위한 신경망 모델
MNIST 기준으로 순방향 신경망은 2차원 이미지를 1차원 벡터로 변환해서 모델을 입력해야 하므로 숫자 인식이 어려움 -> 공간데이터를 1차원으로 변환하는 순간 형상 정보가 분산되기 때문에 정확한 패턴을 인식하기 어려움

고차원 데이터는 차원 별로 크기가 조금만 커져도 전체데이터 크기가 기하급수적으로 증가하기에 파라미터 수도 그만큼 증가하게 된다. 그렇기에 순방향은 이미지 처리에 비 효율적이다.

## 1.1 생체 시각 시스템을 모방한 인공신경망
#### **생체 신경망과 계층적 시각정보처리**
- **뉴런은 아주 좁은 영역의 자극에 반응함** : 뉴런이 자극을 받아들이는 영역을 수용영역이라하는데, 뉴런은 좁은 영역의 자극에 반응하는 국소적인 수용영역을 갖는다.
- **뉴런마다 다른 모양의 특징을 인식하도록 뉴런의 역할이 나뉜다.** : 고양이에게 여러 모양의 형체를 보여줄 때 모양에 따라 서로 다른 뉴런이 반응함
- **뉴런은 계층 정보를 이루며 시각정보를 계층적으로 처리한다.** : 상위 뉴런은 하위 뉴런으로부터 시각정보를 받아서 특징을 인식하는 만큼 더 넓은 수용영역을 가지며, 계층이 높아질수록 수용영역이 점점 넓어져서 최종적으로 전체 시각 영역을 형성함 계층 구조의 가장 하위에 있는 뉴런으로서 단순세포는 선분을 탐지, 복합세포는 단순세포들로부터 시각정보를 받는 뉴런으로 선분의 움직임에 대해 반응하는 위치불변성을 갖는다. 초복합세포는 복합 세포의 상위 뉴런으로서 두 개의 선분이 이루는 모서리나 곡선 또는 선분의 끝을 탐지


# 2. 콘벌루션 신경망의 구조
콘볼루션 계층은 콘벌루션 연산을 통해 이미지의 다양한 특징을 학습하며, 서브 샘플링 계층은 풀링 연산을 통해 이미지의 크기를 줄여서 특징의 작은 이동에 대한 위치 불변성을 갖도록 한다. 콘볼루션 신경망에서 수용영역은 뉴런이 데이터를 전달받은 입력 이미지의 영역이다. 콘볼루션 연산과 서브샘플링 연산이 더 많이 실행될수록 뉴런의 수용영역은 점점 더 넓어지면서 작은 영역의 단순한 특징부터 넓은 영역의 복잡한 특징까지 계층적으로 인식한다.

## 2.1 콘볼루션 연산

convolution이란 두 함수를 곱해서 적분하는 연산, 함수 *f*에  다른 함수 *g*를 적용하여 새로운 함수 *f^*  를  만들 때 사용함  

### 콘볼루션 연산
두 연속 함수 *f(t)* 와 *g(t)* 가 있다고 가정

## 2.2 이미지 콘볼루션 연산
이미지에 대한 콘볼루션은 이미지의 특징을 추출하거나 이미지를 변환할 때 사용

### 경계선 검출 이미지 콘볼루션 연산 정의
이미지에 대한 콘볼루션 연산을 식으로 정의

2차원 이미지가 $I$ , 콘볼루션 필터가 $K$라면 이미지에 대한 콘볼루션 연산 $(I * K)(i, j)$는 다음과 같이 정의됨
함수의 인자 $(i,j)$는 픽셀 인덱스. 이미진는 입력 함수가 되고, 콘볼루션 필터는 가중치함수가 되어 픽셀단위로 가중합산을 함

$$(I *K)(i,j) = \sum_m\sum_nI(m,n)K(i-m,j-n)$$

이미지 처리할 때는 필터를 반전시키지 않기 때문에 콘볼루션 연산이 아닌 교차상관연산을 함
필터가 대칭적인 경우 두 연산은 동일함. 이미지에 대한 교차상관 연산은 다음과 같이 정의함
$$(I *K)(i,j) = \sum_m\sum_nI(m,n)K(i+m,j+n)$$
따라서 콘볼루션 신경망도 교차상관 연산을 하지만 콘볼루션 연산을 한다고 표현

CNN은 둘 중 어떤 연산을 사용하더라도 그에 맞춰서 필터가 학습되는 만큼, 결과에는 차이가 없음

다만 필터를 반전하지 않는 편이 간단하므로 교차상관을 사용함

### 이미지 콘볼루션 연산과정

> 7x7 이미지와 3x3 필터가 있다고 가정

콘볼루션 연산의 첫번째 가중합산은 다음과 같이 계산함. 이미지와 콘볼루션 필터를 왼쪽 위 모서리에 맞춰서 픽셀 단위로 가중 함삽을 하면 새로운 이미지의 첫 번째 픽셀 $y_{11}$이 생성됨

$$
\begin{align*}
y_{11} &= w_{11}x_{11} + w_{12}x_{12} + w_{13}x_{13} \\
&\quad + w_{14}x_{14} + w_{15}x_{15} + w_{16}x_{16} \\
&\quad + w_{17}x_{17} + w_{18}x_{18} + w_{19}x_{19}
\end{align*}
$$


### convolution 필터의 슬라이딩 순서
이미지에서 콘볼루션 필터를 슬라이딩 할때는 2차원 공간에서 슬라이딩 하므로 가로방향과 세로 방향의 순서를 정해야함

보통 가로 한줄 슬라이딩 후 세로 방향으로  한칸 아래로 이동하는 순서로 진행됨


#### 이미지 컨볼루션 필터 설계 예시
각 task에 따라 사용하는 필터가 다름



## 2.3 컨볼루션 신경망의 컨볼루션 연산
컨볼루션 신경망은 이미지의 특징을 추출하기 위해 컨볼루션 필터(*파라미터*)를 학습하며, 특징의 추상화 수준에 따라 컨볼루션 연산을 여러 단계로 계층화해서 실행한다

신경망 모델에서 이미지 컨볼루션 연산을 어떤 방식으로 활용하는지 살펴보면 다음과 같음
> 데이터에 내포된 다양한 특징을 추출하도록 특징에 따라 별도의 컨볼루션 필터를 둔다. 컨볼루션 필터별로 서로다른 특징을 추출하므로, 데이터의 특징이 다양하다면 그만큼 컨볼루션 필터개수를 늘려줘야한다. 
> 하지만  이미지가 몇 개의 특징을 내포하고 있는지 미리 알기는 어렵기에 검증과정을 통해서 필터 개수를 조정해야한다. 
> 
> 컨볼루션 필터의 크기와 개수는 계층별로 특징의 추상화 수준에 따라 다르게 설계해야한다. 추상화 수준이 높아질수록 특징이 세분화 되므로 더 많은 종류의 필터가 필요함
> 
> 컨볼루션 필터의 값은 데이터의 특징을 잘 추출하도록 학습을 통해 정한다. 즉 미리 설계된 컨볼루션 필터를 사용하지 않고, 이미지의 특징에 따라 최적의 값으로 정의되도록 학습과정에서 결정함

### 입력데이터의 형태
컨볼루션 신경망의 입력데이터가 이미지라고 가정, 이미지는 눈으로 볼때는 2차원이지만, 색깔별 빛의 강도를 나타내는 채널(channel)이 존재하기 때문에 3차원으로 표현(RGB 채널, 투명도로 하면 RGBA, 흑백이미지는 한개의 채널)

따라서 컨볼루션 신경망의 입력 데이터는 *[Width] X [height] X [Depth]* 로 표현되는 3차원 텐서로 나타낼 수 있음
![[스크린샷 2024-05-26 21.05.35.png]]



[Width] x [Height] 는 공간특징을 표현, [Depth]는 채널 특징을 표현한다. (흑백은 뎁스1, 컬러는 뎁스3, 투명도포함 뎁스 4)

### 컨볼루션 필터의 형태 
컨볼루션 필터도 3차원 텐서로 정의됨. 표준 컨볼루션 연산은 채널 방향으로 슬라이딩하지 않으므로, 컨볼루션 필터의 Depth는 입력데이터의 Depth와 동일해야한다. 

![[스크린샷 2024-05-26 21.14.22.png]]

### 컨볼루션 필터의 크기와 개수
뉴런의 수용영역은 컨볼루션 필터의 크기에 따라 달라진다. 

만일 모든 계층에서 작은 컨볼루션 필터를 사용한다면 수용영역을 조금씩 늘려가며 특징을 학습하게 되고, 모든 계층에서 큰 컨볼루션 필터를 사용한다면, 수용영역을 빠르게 확장하며 특징을 학습하게 된다. 

따라서 컨볼루션 필터의 크기에 따라 신경망의 성능도 달라지며, 컨볼루션 필터의 크기는 신경망 성능이 최대화 되도록 정해야 한다.

일반적으로  3x3, 5x5, 7x7을 사용함


컨볼루션 필터의 개수는 이미지의 복잡도에 따라 달라지는데, 컨볼루션 필터마다 다른 특징을 학습하기 때문에 이미지의 특징이 다양할수록 더 많은 필터를 사용해야 한다.

### 표준 컨볼루션 연산
컨볼루션 신경망에서 표준 컨볼루션 연산은 모든 채널에 대해 한꺼번에 가중 합산을 한다.
![[스크린샷 2024-05-26 21.22.29.png]]

![[convol.gif]]

### 컨볼루션 신경망의 뉴런?
이미지와 컨볼루션 필터가 가중합산연산을 할 때마다 하나의 뉴런이 실행된다

컨볼루션을 할 때 겹쳐진 5 x 5 x 3 이미지 영역과 5 x 5 x 3 컨볼루션 필터를 크기가 75인 1차원 벡터로 변환한다고 가정할 때

이미지 영역은 입력벡터 $x$고  컨볼루션 필터는 가중치벡터 $w$라고 하면 이미지와 컨볼루션 필터의 가중합산연산은 뉴런에서 입력과 가중치의 가중합산 $w^Tx$가 된다. 여기에 편향 $b$를 더하면 $w^Tx+b$가 된다.
![[스크린샷 2024-05-26 21.47.31.png]]
### 지역연결을 갖고 가중치를 공유하는 뉴런
뉴런 관점에서 보면 이미지 영역과 컨볼루션 필터가 가중합산될 때 뉴런의 가중합산연산이 실행된 것이다. 

다만 지금까지 봐왔던 완전연결층과 달리, 입력 데이터의 모든차원과 모두 연결되는 대신 컨볼루션 필터와 겹쳐진 영역에만 연결되는 **지역연결**을 갖는 뉴런이다. 

또한 뉴런의 가중치에 해당하는 컨볼루션 필터는 모든 뉴런에서 재사용이 됨

### 액티베이션 맵 (피처 맵; feature map)
컨볼루션 연산 결과로 만들어지는 이미지를 **액티베이션 맵(activation map)** 이라고 한다 . 

피처맵이라고 부르기도 하며, 피처맵의 픽셀은 각 뉴런의 출력이다.

따라서 한 계층에는 액티베이션 맵과 같은 3차원 텐서 형태의 뉴런들이 모여있다고 생각할 수 있다. 이들 뉴런은 컨볼루션 필터 크기만큼의 지역연결을 가지고 있으며, 입력 데이터의지역 특성을 학습한다.

또한 가중치를 공유하기에 학습된 특징이 나타나면 위치에 상관없이 인식한다.

학습된 특징에 대한 일종의 패턴 매핑을 하는 것인데, 이 성질을 **이동등변선** 이라고 한다. 

### 컨볼루션 필터 개수와 같은 액티베이션 맵의 채널 수
![[Pasted image 20240526213721.png]]

![[Pasted image 20240526213908.png]]

![[스크린샷 2024-05-26 21.47.46.png]]



### 두 번째 계층의 컨볼루션 연산
첫 번째 계층에서 출력된 28 x 28 x N 액티베이션 맵은 두 번째 계층의 입력 데이터가 되머 또 다른 연산을 수행한다.

이때 두 번째 계층의 컨볼루션 필터의 채널 수는 입력 데이터의 채널수와 같아야 하므로 N이어야 한다.

두 번째 계층의 컨볼루션 필터가 M개라면 채널 개수가 M인 액티베이션 맵이 만들어진다.

28 x 28 x N 입력 데이터를 M개의 5x5xN 컨볼루션 필터로 컨볼루션하면 24x24xM의 액티베이션 맵이 생성된다.

### 뉴런의 활성함수 실행
각 뉴런은 액티베이션 맵과 동일한 3차원 텐서 형태로 배열되어 있다.

3차원 텐서에 활성함수를 실행하면, 모든 뉴런에 활성함수가 일괄적으로 실행된다.

#### 활성 함수 적용 과정

CNN의 한 계층을 거친 후, 출력은 다시 3차원 텐서로 나타납니다. 예를 들어, 컨볼루션 계층을 지나고 나면 활성화 맵이 생성됩니다. 활성화 맵도 3차원 텐서입니다.

각 요소는 하나의 뉴런을 나타내며, 이 뉴런들의 출력에 활성 함수를 적용합니다. “모든 뉴런에 활성 함수가 일괄로 실행된다”는 의미는 다음과 같습니다:

1.	텐서의 각 요소에 대해 활성 함수 적용:
	•	3차원 텐서  T 가 있다고 가정합시다. 이 텐서의 각 요소는  T_{ijk} 로 표현할 수 있습니다.
	•	활성 함수  f 를 텐서  T 의 각 요소에 개별적으로 적용합니다.
	•	즉, 모든  T_{ijk} 에 대해  f(T_{ijk}) 를 계산합니다.

2.	일괄 적용:
	•	이 과정은 텐서의 모든 요소에 대해 동시에 수행됩니다. 예를 들어, ReLU 활성 함수가 텐서에 적용된다면, 텐서의 각 요소가 ReLU를 통해 변환됩니다.
	•	이를 통해 텐서의 모든 값이 변환된 새로운 텐서가 생성됩니다.

예시

32x32x3 크기의 RGB 이미지를 입력으로 하는 경우, 첫 번째 컨볼루션 계층을 통해 28x28xN 크기의 활성화 맵이 생성되었다고 가정합시다. 활성 함수를 ReLU로 설정했을 때, 각 요소에 대해 ReLU를 적용합니다.

•	활성화 맵의 각 요소  A_{ijk} 에 대해  f(A_{ijk}) = \max(0, A_{ijk}) 를 계산합니다.
•	이 과정이 활성화 맵의 모든 요소에 일괄적으로 적용됩니다.
```python
import numpy as np

# 예시 텐서 생성 (3x3x2 텐서)
tensor = np.array([
    [[-1, 2], [3, -4], [5, 6]],
    [[-7, 8], [9, -10], [11, 12]],
    [[-13, 14], [15, -16], [17, 18]]
])

# ReLU 활성 함수 정의
def relu(x):
    return np.maximum(0, x)

# ReLU 함수 적용
activated_tensor = relu(tensor)

activated_tensor
```

```
array([[[ 0,  2],
        [ 3,  0],
        [ 5,  6]],

       [[ 0,  8],
        [ 9,  0],
        [11, 12]],

       [[ 0, 14],
        [15,  0],
        [17, 18]]])

```

### 순방향 신경망의 계층과 비교
컨볼루션 신경망의 계층은 모든 입력데이터와 출력데이터가 1차원에서 3차원으로 확장되어 있고, 그에 따라 뉴런의 배열도 3차원으로 확장되어 있다. 

또한 뉴런은 컨볼루션 필터 크기의 지역 연결을 가지며, 같은 채널의 뉴런들은 컨볼루션 필터의 가중치를 공유한다.




## 2.4 서브샘플링 연산
> **서브샘플링**은 데이터를 낮은 빈도로 샘플링 했을 때의 샘플을 근사하는 연산이다.
> 
> 데이터가 이미지라면 이미지 크기를 줄이는 연산이 되어 **다운샘플링(down sampling)** 이라 부른다.
> 
> 컨볼루션 신경망은 이미지 크기를 줄이기 위해 **풀링연산(pooling)** 을 사용했다.
> 
> 다른 방법으로는 슬라이딩 간격을 늘리는 방법이 있다

### 풀링연산을 이용한 서브샘플링 연산
풀링연산은 이미지 상에서 풀링 필터를 슬라이딩 하면서 요약 통계량을 구하는 연산이다.

주로 평균이나 최댓값과 같은 요약통계량을 사용하지만 최소, 가중합산, $L_2$ 노름 등도 사용할 수 있다.

풀링 연산에서 사용하는 요약 통계량에 따라 추출하는 특징이 달라진다.

최대값을 사용하는 풀링연산을 **Max pooling** 이라 하며, 입력데이터의 가장 두드러진 특징을 추출한다.

한편 평균을 사용하는 풀링연산을 **average pooling**이라 하며, 평균적인 특징을 추출한다.


![](https://i.imgur.com/21gGji8.png)
 


풀링연산을 사용해 서브샘플링을 하면 보통 2x2 필터를 사용하고 필터 크기만큼 슬라이딩한다.

### 컨볼루션을 이용한 서브샘플링 연산
슬라이딩의 간격을 늘려 서브샘플링을 진행할 수 있음

### 컨볼루션 신경망에서 풀링연산
컨볼루션 신경망에서 풀링연산을 할때는 계층별로 풀링 필터의 크기와 슬라이딩 간격을 지정해준다.

풀링 필터는 지정된 요약 통계량만 구하면 되므로 학습을 진행하지 않는다(컨볼루션 필터와 달리)

단, 풀링연산은 컨볼루션 연산과 같은 방식으로 슬라이딩하며 채널별로 요약통계를 구하기 때문에 채널수는 유지된다. 

### 풀링 필터의 크기와 위치불변성
최근에는 신경망을 깊게 쌓기 위해서 컨볼루션 연산을 여러번 하고 풀링 연산을 진행하기도 한다.

플링 필터의 크기를 정하는 문제는 어떤 크기의 수용영역 내에서 위치 불편성을 줄 것인가 결정하는 문제이다.

보통 2x2지만 신경망의 성능이 최대화되도록 정의해야한다.

## 2.5 스트라이드
컨볼루션 연산과 풀링연산을 할 때 필터의 슬라이딩 간격을 **스트라이드**라고 한다. 대부분 서브 샘플링 없이 특징을 학습할 때는 한칸씩 슬라이딩하고, 서브샘플링을 할 때는 두칸씩 슬라이딩하지만, 종종 더 크게 두기도 한다.

### 스트라이드 크기별 컨볼루션 연산
$$O = {N-F\over S} + 1$$

위와 같은 식을 만족해야함

## 2.6 패딩
컨볼루션 연산을 진행한다면 필터가 이미지 안에서만 슬라이딩 하므로 출력이미지의 크기는 입력이미지의 크기보다 작아질수밖에 없다.

따라서 컨볼루션 연산을 여러번 하면 크기가 점점 줄어들다가 어느 순간 연산을 할 수 없는 크기로 변한다.

즉 컨볼루션 연산 횟수가 제한이 되는 문제가 발생한다.

횟수가 제한되면 컨볼루션 신경망에서는 계층 수가 제한되기 때문에 신경망을 원하는대로 깊게 만들 수 없게 된다.

이러한 이유로 이미지 크기를 유지하기 위해 이미지에 픽셀을 추가해서 크기를 늘려야 하는데 이와 같은 방법을 이미지 **패딩(Padding)** 이라 한다. 패딩은 데이터를 일정 크기로 만들기 위해 더미 데이터를 추가하는 방법이다.

컨볼루션 필터의 크기가 $F$라면 컨볼루션 연산을 수행할 때마다 이미지 크기가 $F-1$씩 작아진다.

### 이미지 크기를 유지하기 위한 패딩처리
컨볼루션 연산 후에도 이미지 크기를 유지하려면 줄어든 픽셀만큼 이미지 패딩을 하면된다.

즉 연산 후, $F-1$픽셀만큼 이미지가 작아진다면 이미지에 $F-1$픽셀을 패딩한다.

이렇게 한다면 이미지 크기가 유지되면서 연산 횟수의 제한도 사라지게 된다.

### 패딩을 고려한 컨볼루션 연산의 출력 크기
패딩 후 연산을 진행했을 때 출력이미지의 크기는 다음 식으로 계산할 수 있다.

이미지 크기가 N, 패딩이 P일때 패딩된이미지 크기는 $N+2 \times P$ 가 되므로 다음 식같이 정리된다.

$$O = {(N+2 \times P)-F \over S}+1 $$

## 2.7 신경망 깊이와 수용영역의 관계

### 뉴런의 수용영역이 계층에 따라 변화하는 과정
계층이 깊어질수록 컨볼루션 연산 횟수가 많아지므로 뉴런의 수용영역이 점점 커진다.

# 3. 컨볼루션 신경망의 가정상황
> 컨볼루션 신경망은 지역연결을 갖는 모델이므로 파라미터를 일부만 사용한다. 사용하지 않은 파라미터는 해당 파라미터의 확룔이 없는 것으로 간주하는 _매우 강한 사전분포(infinitely strong prior)_ 를 가정
> 
>  이런 가정에서 컨볼루션 연산과 풀링 연산이 정의 되었기 때문에 컨볼루션 신경망은 _희소연결(Sparse connectivity)_ 를 갖고 _파라미터 공유(parameter sharing)_ 를 하는 구조를 이루며, 그에 따라 _이동등변성(transiation equivariance)_ 과 _위치불변성(positional invariance)_ 을 갖는다. 
>  
>  이러한 구조와 성질 때문에 컨볼루션 신경망은 공간데이터를 처리할 때 성능이 극대화된다. 

## 3.1 컨볼루션 연산의 성질
> 매우 강한 사전 분포를 가정

컨볼루션 연산과정에서 컨볼루션 필터와 겹치는 영역에만 연결되고 나머지 영역에서는 연결이 없는 희소 연결을 가진다. 

또한 동일한 컨볼루션 필터로 연산하기 때문에 같은 계층의 모든 뉴런은 파라미터를 공유한다. 

컨볼루션 신경망은 희소연결을 가지고 파라미터를 공유하므로 위치에 상관없이 동일한 지역 특징을 인식할 수 있는 이동등변성을 가진다.

### 희소연결성질
만약 매우 강한 사전분포가 가정되지 않았다면 뉴런이 모든 입력에 대해 연결을 갖는 완전 연결을 가진다.

이때 입력이 m개고, 뉴런이 n개면 전체 파라미터 수는 $O(m \times n)$이 된다.

![](https://i.imgur.com/eQF5v9z.png)
 위 그림이 컨볼루션 연산시 수용영역, 아래가 FC 레이어의 수용영역

희소 연결을 가짐녀 파라미터가 줄고, 메모리와 계산이 절약됨

### 파라미터 공유성질
 둘 이상의 함수에 같은 매개변수를 사용하는 것  
합성곱 신경망에서 핵의 각 성분은 입력의 모든 곳에 쓰인다.  
- 모형이 저장해야하는 매개변수 개수를 k로 줄인다  
실행시간은 O(kn)이지만 k는 m보다 작고, mxn에 비하면 k는 사실상 무시할 정도로 작다.  
=> 조밀한 행렬 곱셈보다 메모리 요구량과 통계적 효율성 면에서 뛰어나다.
![](https://i.imgur.com/gstemB5.png)


### 이동등변성
희소연결과 파라미터 공유 성질로 인해 생기는 컨볼루션 연산의 주요 성질이 이동등변성이다. 

이동등변성은 위치에 상관없이 특징을 인식하는 성질인데, 아래 그림에서 입력 데이터 2가 이동하더라도 컨볼루션 연산으로 추출된 특징은 같다. 

어느 위치에 나타나든 동일한 방식으로 특징을 인식하는 성질을 말한다.
![](https://i.imgur.com/AeVAhjA.png)



수식으로 나타내면 다음과 같다. 
$$f(g(x)) = g(f(x))$$

하지만 크기 조정과 회전에 대해서는 등가 성질을 가지고 있지 않는다. 따라서 이미지 크기를 조정하거나 회전했을 때 동일한 특징을 인식하도록 하려면 간단하게는 데이터를 증강하거나, 나은 성능을 기대하려면 이미지 내의 객체를 다양한 크기로 인식하거나 여러 각도로 회전되어도 인식하도록 개선된 모델을 사용해야 한다.

## 3.2 풀링 연산의 성질
풀링 연산은 위치 불변성을 가진다. 맥스 풀링을 한다면, 가운데 있는 최댓값이 어디로 이동하든 결과는 동일하다

이처럼 입력이 아주 작게 이동했을 때 출력이 바뀌는 성질을 위치불변성이라고 한다. 

아주 작은 이동 변환을 g(x)라 하고, 풀링연산을 f(x)라 했을 때, 이동불변성을 갖는다면 다음과 가탇

$$f(x) = f(g(x))$$

# 4. 개선된 컨볼루션 연산
> 지금까지 연산에서는 몇가지 성능적 제한이 존재한다.
> 
>  1. 파라미터 수와 계산량이 많다.
>  2. 죽은 채널이 발생해도 알기 어렵다
>  3. 여러 채널에 대해 한꺼번에 연산하므로 공간특징과 채널 특징이 구분되지 않는다.

## 4.1 팽창 컨볼루션(Dilated convolution filter)
### 뉴런의 수용영역을 넓힐 때 문제점
뉴런의 수용영역을 넓히려면 필터의 크기를 키우거나, 신경망의 깊이를 늘리거나, 샘플링 계층을 추가하면 된다.

하지만 이러한 방법들은 문제가 존재한다.

필터를 키우거나 신경망의 깊이를 늘리면 파라미터 수와 계산량이 많아지고, 서브샘플링 게층을 추가하면 이미지의 공간 특징이 손실되기 때문에 세그멘테이션과 같이 공간 특징을 활용하는 모델에는 성능에 좋지 않은 영향을 미친다.

### 공간 특징을 유지하며 수용영역을 넓히는 팽창 컨볼루션
파라미터 수와 계산량을 늘리지 않고 공간 특징을 유지하면서 수용영역을 넓히는 방법은 필터의 수용 픽셀 간격을 띄워서 필터를 넓게 만드는 것이다. 
![](https://i.imgur.com/XAlkKKu.gif)



## 4.2 점별 컨볼루션(Pointwise Convolution)
점별 컨볼루션 (Pointwise Convolution)은 가로 x 세로 크기가 $1\times 1$인 컨볼루션 필터를 사용하므로 $1\times 1$ 컨볼루션이라 부리기도 한다. 

![](https://i.imgur.com/fQpy45S.png)


픽셀별로 채널에 대해서만 컨볼루션 하기 때문에 피처맵의 가로 세로 크기는 변하지 않고 채널 수만 달라진다.

점별 컨볼루션을 사용하게 되면 채널 특징을 학습할 수 있으며, 죽은 채널의 영향을 줄일 수 있다.

또한 채널 수를 줄이거나 늘릴 수 있어서 컨볼루션 계산량을 조절할 때 사용한다.

> _인셉션, 레즈넷, 모바일넷, 스퀴즈넷 과 같은 모델에서 사용_

## 4.3 그룹 컨볼루션 (Group Convolution)
그룹 컨볼루션은 채널을 여러 그룹으로 나눠서 컨볼루션 하는 방식이다.

표준 컨볼루션보다 파라미터와 계산이 절약되며, 채널 간에 상관관계를 갖는 구조를 학습할 수 있다.

표준 컨볼루션의 경우 인접한 두 계층의 컨볼루션 필터간 상관관계가 잘 생기지 않지만, 그룹 컨볼루션은 인접한 두 계층의 필터 그룹간에는 높은 상관관계가 있으며 구조적인 학습을 할 수 있다. 

따라서 상관관계가 낮은 채널 간에는 연결되어 있지 않으므로 파라미터 수가 줄어들고 과적합이 방지되는 정규화 효과가 생긴다.

## 4.4 깊이별 컨볼루션 (Depthwise convolution)
표준 컨볼루션의 경우 여러 채널에 대해 한꺼번에 연산하게 되므로 채널별로 공간 특징을 학습할 수 없다.

깊이별 컨볼루션방법에서는 각 채널의 공간특징을 학습할 수 있도록 채널별로 컨볼루션 연산을 수행하고, 그 결과를 다시 결합한다.

![](https://i.imgur.com/SSmZ0YG.png)


깊이별 컨볼루션은 입력과 출력의 채널수가 동일하며 표준 컨볼루션보다 파라미터와 계산량이 절약된다. 

그룹 컨볼루션의 그룹별 채널 수가 1개이면, 깊이별 컨볼루션과 같기 때문에 깊이별컨볼루션은 그룹 컨볼루션의 특별한 경우이다.

## 4.5 깊이별 분리 컨볼루션(Depthwise seperable Convolution)
깊이별 분리 컨볼루션은 깊이별 컨볼루션과 점별 컨볼루션을 결합한 방식이다.

공간 특징과 채널 특징을 별도로 학습하며 표준 컨볼루션보다 8~9배 정도 계산량이 줄어든다.


## 4.6 셔플 그룹 컨볼루션
그룹 컨볼루션은 같은 채널 안에서만 정보가 흐르고, 그룹간 서로 정보를 교환하지 않는다. 하지만 채널 그룹간에 정보를 교환하면 표현이 강화될 수 있는데, 이런 아이디어는 셔플넷의 **셔플 컨볼루션**이란 이름으로 제안되었다.

셔플 컨볼루션은 주기적으로 그룹 간 채널을 섞어서 정보가 교환되도록 만든 교환 컨볼루션 방식이다.

## 4.7 공간 분리 컨볼루션
정사각형 컨볼루션 필터를 가로 방향 필터와 세로방향 필터로 인수분해한 방법
> 인셉션에서 사용





# 5. 업샘플링
> 컨볼루션 신경망에서는 이미지 크기를 줄이는 연산 뿐만 아니라 이미지 크기를 키우는 연산도 필요하다.
> 
> 이를 **업샘플링 (Upsampling)** 연산이라 하며, 이미지 생성 모델이나 세그멘테이션 모델에서 사용한다.
> 
> 이미지 생성 모델은 다음과 같이 저차원의 고양이 잠재 벡터를 고차원의 고양이 이미지로 변화하며 저차원에서 고차원으로 데이터도 변활할 때 업샘플링 연산을 수행한다.


## 5.1 언풀링
언풀링은 풀링 연산의 반대 연산으로, 요약된 통계 데이터를 요약하기 전 크기의 데이터로 복구하는 연산이다.

예를 들어 $2\times 2$이미지를 $2\times 2$ 필터를 사용해 $4\times 4$이미지로 언풀링 한다 가정할 때 어떤 값으로 채울지에 따라 다른 종류의 언풀링이 된다.

### 바늘방석 언풀링(bed of nails )
바늘방석 언풀링은 $2\times 2$ 영역의 첫 번째 픽셀은 원래 값으로 채우고 나머지 픽셀은 0으로 채우는 방법이다.

바늘방석 모양과 같이 특정 위치의 픽셀값이 튀어나와있고, 나머지는 값이 없는 상태로 평평하기 때문에 바늘방석 언풀링이라 부른다.

![](https://i.imgur.com/nh0FJwN.png)


### 최근접 이웃 언풀링(nearest neighbor)
최근접 이웃 언풀링은 $2\times 2$ 영역을 모두 원래의 픽셀값으로 채우는 방법이다.

이름과 같이 첫 번째 픽셀은 원래 값으로 채우고 나머지 픽셀에는 가장 가까운 이웃인 첫번째 픽셀과 같은 값으로 채운다. 

**블록을 같은 값으로 채우므로 전체 이미지에 블록 모양의 패턴이 생긴다.**
![](https://i.imgur.com/4YG0f5N.png)


### 맥스 언풀링(Max unpooling)
맥스 언풀링은 다운 샘플링과 업샘플링이 대칭을 이루는 모델 구조에서만 사용할 수 있는 방식이다.

맥스풀링을 할때 최댓값의 위치를 기억해 두었다가 언풀링을 할 때 기억해 둔 위치로 값을 복원하고 나머지는 0으로 채운다.
![](https://i.imgur.com/eFYcIOj.png)



## 5.2 트랜스포즈 컨볼루션
언풀링 방식은 사전에 정의된 규칙에 따라 업샘플링을 진행한다. 하지만 이런 규칙이 과연 모든 경우에 가장 적합한 방식이냐는 질문에는 답을 할 수 없다. 상황에 따라 더 나은 결과를 만들도록 규칙을 학습할 수 도 있을 것이다.

업샘플링도 학습하도록 만든 방식이 트랜스포즈 컨볼루션이다.

### 트랜스포즈 컨볼루션 연산
입력 이미지의 첫 번째 픽셀과 트랜스포즈 컨볼루션 필터를 곱해서 출력 이미지 영역을 생성한다. 

두번째 픽셀과 필터를 곱해서 스트라이드 만큼 오른쪽으로 이동해서 출력 이미지 영역을 생성한 뒤 첫번째 출력 이미지를 만든다.

이때 겹치는 영역이 생기면, 그부분의 픽셀 값은 더해준다.

![](https://i.imgur.com/wnWOlLJ.png)



### 바둑판무늬 제거를 위한 스트라이드 조절
주의해야할 점은 겹쳐진 부분의 픽셀값이 더해짐녀 바둑판 무늬가 될 수 있다느 는 점이다.


무늬를 없애려면 모든 픽셀이 같은 횟수로 겹쳐지도록 필터와 스트라이드의 크기를 조절해야 한다.

스트라이드를 조절하면 모든 픽셀이 동일하게 2번씩 겹치므로 무늬가 생기지 않는다.

### 트랜스포즈 컨볼루션이라 부르는 이유
컨볼루션 행렬의 전치행렬로 연산을 표현할 수 있기 때문이다.
![](https://i.imgur.com/IPFW1sd.png)


입력 벡터가 $x^T = (a,b)$, 트랜스포즈 컨볼루션 필터가 $w^T = (x,y,z)$이고 스트라이드 2라고 가정한다.

먼저 입력벡터의 첫번째픽셀 a와 필터를 곱하면 $(ax, ay, az)^T$ 가 만들어 지고, 두 번째 픽셀 b와 필터를 곱하면 $(bx, by, bz)^T$가 만들어진다. 스트라이드가 2이므로 생성된 두 벡터를 띄워서 더하면 한 픽셀이 겹쳐서 크기가 5인 $(ax, ay, az + bx, by, bz)^T$벡터가 된다. 스트라이드가 2이므로 크기가 4인 벡터가 되어야 하므로 마지막 요소를 버리고 $(ax, ay, az + bx, by)^T$를 생성한다.

### 컨볼루션 행렬의 전치행렬로 표현되는 트랜스포즈 컨볼루션 연산
![](https://i.imgur.com/fUYyXx0.png)

![](https://i.imgur.com/SvDVQCT.png)



# 강의내용

## 질문 -> 20분까지
인풋에 대해 커널을 통해 결과를 만들어내는게 컨볼루션, 커널이 필터, 결과를 통해 인풋의 여러 미쳐를 뽑아내고, 뽑아낸 피쳐를 이용해 모델을 학습?

-> 뽑아낸 피처를 통

max fooling을 사용하는 이유?
avg나 max냐 정답은 없음 -> 하지만 max를 더 많이 쓰는데 noise robustic함


## Architecture of CNN
- cnn진행 후 fc진행

## Fully Connected layer
- 좀 오버헤드임
- classification -> softmax

## 초창기 cnn기반 classification : Lenet-5
cnn -> cnn -> fc -> fc -> classification

## Variants of the Convolution
## Receptive Field
