#deep_learning #CNN #Architecture 


# 1. LeNet - 5
> 최초의 컨볼루션 신경망

![](https://i.imgur.com/ZQFiXiX.png)

## 1.1 모델구조
르넷-5는 `CONV - POOL - CONV - POOL - FC - FC - FC`로 구성된 7계층 모델이다.

![](https://i.imgur.com/JJvDwge.png)


컨볼루션 계층과 풀링 계층을 2번 씩 반복한 뒤 완전 연결 3계층으로 연결되는 구조다.

컨볼루션 계층과 풀링 계층은 생체 신경망의 시각 영역을, 완전연결계층은 연관영역을 모델링 했다.


# 2. AlexNet
`이미지넷(imageNet)` 은 약 1,400만 개의 이미지로 구성된 이미지 데이터 베이스로서 20000만여개의 카테고리를 포함한다.

그중 알렉스넷은 이미지넷을 활용한 객체인식오류를 압도적으로 낮추며 1위를 차지한 최초의 컨볼루션 신경망 모델이다.

## 2.1 모델 구조
알렉스 넷은 2개의 GPU에서 실행되는 병렬처리 구조로 설계되었다. 

~~당시 gpu로는 한개로 실행시킬 수 없어 병렬처리 구조로 설계하고 2개의 gpu에서 실행~~

알렉스 넷은 컨볼루션 필터를 두 그룹으로 나눈 뒤 그룹별로 GPU를 할당하여 처리하고, 중간 계층에서 정보를 교환하여 최종 결과를 한쪽 그룹으로 합친다.

### 병렬처리 방식
첫 번째 계층에 $277 \times 277 \times 3$ 입력 데이터가 들어오면 그룹별로 48개 컨볼루션 필터가 연산을 수행한다.

정보를 교환하기 위해 Conv3과 Conv5, FC6, FC7 계층에서 그룹 간 출력을 교환하여 출력 계층인 FC8에서 전체 결과를 합친다.

![](https://i.imgur.com/oX9N3Pt.png)


이미넷으로 알렉스 넷을 훈련했을 때 5~6일 정도 소요되었고, 이들이 사용한 그룹을 나눠 처리하는 방식은 그룹 컨볼루션이란 이름으로 레즈넥스트 모델에 도입되어 그룹 내에서 채널 간의 상관관계 구조를 학습하는 용도로 활용되고 있다.

### 모델구조
알렉스넷의 병렬처리 구조를 하나의 구조로 합치면 다음과 같다.

알렉스 넷은 `conv-conv-conv-conv-conv-fc-fc-fc`로 구성된 8계층 모델이다.

컨볼루션 5계층이 완전연결 3계층과 연결된 구조이다. (이때 풀링은 컨볼루션 계층에 포함된다.)

알렉스넷의 첫 번째 계층은 `11x11, 4` 컨볼루션 연산을 진행한다. 

상대적으로 큰 컨볼루션 피러와 스트라이드를 사용하므로 학습이 잘 안되는 문제가 존재하며, 나머지 컨볼루션 계층은 `3x3, 1` 컨볼루션 연산을 한다.

CONV1, CONV2, CONV5에서는 `3x3, 2` 로 맥스 풀링하며 한 픽셀씩 겹치도록 풀링한다.

CONV1과 CONV2에서는 지역응답정규화라고 불리는 _LRN(local response normalization)_ 방식으로 출력을 정규화한다.

LRN정규화는 픽셀별로 이웃 채널의 픽셀을 이용하여 정규화하는 방식으로 지금은 잘 사용하지 않는다.

ReLU의 출력이 무한히 커질 수 있으므로 이를 막기 위한 정규화로 도입되었다. 227x227x3 입력이 들어왔을 때, 첫 번째 계층은 컨볼루션 맥스풀링 정규화 순서로 실행하며, 드랍아웃은 FC6, FC7계층에만 적용되어 있다.

### 모델 파라미터 수
알렉스 넷의 파라미터 수는 6천200백만 개에 달한다.

알렉스넷의 파라미터는 FC계층에 집중되어있는데, 초기 컨볼루션 신경망 모델들은 생체 신경망의 영역의 연관영역을 모델링하기 위해 FC계층을 포함하지만, 그 결과 파라미터가 과도하게 쓰이는 문제가 존재한다. 

구글넷 이후 나온 모델들은 파라미터를 줄이기 위해 출력 계층을 제외하고 모든 계층을 컨볼루션계층으로 구성한다.

## 2.2 훈련방식
- GPU를 활용함으로써 압도적인 성능 향상
- LRN, 드롭아웃(p = 0.5), $L_2$정규화, 데이터 증강 등 정규화 기법사용
- 앙상블 (모델 7개)
- SGD 모멘텀
- 배치크기 128
- 학습률 : $1e-2$

# 3. 제프에프넷(ZFNet)
![](https://i.imgur.com/gUG4ISq.png)


제프에프넷은 모델 시각화 방식으로 알렉스넷의 문제점을 분석하고 개선했다.

## 3.1 모델 구조
기본 구조는 알렉스넷과 동일하지만, 다음과 같이 일부 개선되었다.

- Conv1의 컨볼루션을 11x11,4에서 7x7,2 로 바꿨다.
- conv3,conv4,conv5의 필터 개수를 384,384,256에서 512,1024,512로 조정했다.
- 모델을 학습하기 위해 그룹을 하나로 합침

Conv1 컨볼루션 연산을 바꾼 이유는, 알렉스넷의 시각화 결과 첫번째 계층이 잘 학습되지 않는다는 사실을 발견했기 때문이다.

지나치게 크게 설계된 수용영역 때문이었는데, 컨볼루션 필터의 크기와 스트라이드를 조정한 뒤 정상적으로 학습이 되었고, 이를 시각화를 통해 확인했다.

## 3.2 모델 시각화 방식
시각화를 통해 다음과 같은 사실을 입증함
> - 컨볼루션 신경망의 계층이 높아질수록 수용영역이 넓어지고, 지역적 특징에서 전역적 특징으로 학습내용이 변경된다.
> - 낮은 계층에서 먼저 학습되기 시작해서 점점 높은 계층으로 학습이 진행된다.
> - 입력에 작은 변화가 있어도 동일한 결과를 출력하는 _위치불변성_ 을 갖는다.
> - 특징을 포착할 때 모양은 물론이고 위치까지 가늠한다.

### 디컨볼루션 네트워크
시각화한 방법으로는 컨볼루션의 역연산으로 액티베이션 뱁을 픽셀공간에 투영하는 방식이다.

이를 위해 디컨볼루션 네트워크를 만들었는데, 다음 그림과정 계층에 액티베이션 맵을 시각화하려면, 짝을 이룰 디 컨볼루션 계층에 액티베이션 맵을 입력해서 입력 계층 방향으로 디컨볼루션을 수행한다.


# 4. VGG Net
> 작은 필터를 사용하는 대신 깊은 신경망을 만들자

## 4.1 설계 사상
VGG는 신경망이 깊어질수록 수용영역이 넓어지는원리를 이용하여, 필터를 작게 만들어서 파라미터 수를 줄이고 대신 신경망을 깊게 하여 수용영역을 충분히 설계했다.

### 큰 컨볼루션 필터 VS. 작은 컨볼루션 필터
뉴런의 수용영역은 컨볼루션 필터의 크기, 스트라이드, 계층에 따라 정해진다. (예를 들어 수용영역이 5인 뉴런을 만들려면 한 계층에 크기가 5인 컨볼루션 필터를 사용해도 되지만, 두 계층에 각각 3인 컨볼루션 필터를 사용할 수도 있다)

같은 수용영역을 나타내는 두 방식 중 작은 필터를 사용해서 여러 계층으로 쌓는 방식이 파라미터 수를 줄이는 방식이라고 말할 수 있다.

## 4.2 모델 구조
VGG는 11계층부터 13계층, 16게층, 19계층까지 총 6가지 종류의 모델로 구성된다.

### 다양한 계층으로 구성된 VGG
그 중 16계층을 제일 많이 사용하며, 짧게 VGG16이라 부른다. 19계층을 사용한 경우는 파라미터수는 많지만 성능차가 크지않아 많이 쓰이지 않는다.

### VGG16 모델 구조
VGG16은 계층별로 특징을 추출해서 사용할 때가 많으므로 계층마다 이름이 있다.

또한 출력 크기에 따라 컨볼루션 계층을 그룹으로 묶어서 부른다. 그래서 5개의 그룹 CONV1,CONV2,CONV3,CONV4,CONV5이 완전 연결 계층으로 연결되는 구조를 이룬다.
![](https://i.imgur.com/XB4p2p4.png)



### FC7 계층의 활용
이미지의 특징을 추출할 때 많이 사용한다. 예를 들어 스타일 변환을 할 때 VGG를 사용해서 일부 계층의 특징으로 스타일을 생성한다. 

특히 FC7의 특징은 이미지를 설명하는 콘텍스트 벡터로 쓰이곤 한다. FC7이 출력 직전의 계층이므로 FC7에서 이미지 표현이 가장 추상화된 상태이기 때문이다.

### 모델 파라미터 수
초기계층은 메모리 사용량이 많고, 후반 계층은 파라미터가 집중되어있다.
- 메모리 사용량 96m
- 파라미터 수 : 138M

# 5. 구글넷
구글넷은 전형적인 컨볼루션 신경망의 구조를 탈피하여 네트워크 모듈을 쌓는 방식의 네트워크 속 네트워크 구조로 설계되었다.

전체 파라미터 수는 5m으로 알렉스넷보다 12배 적으면서도 깊은 신경망을 실현할 수 있는 효율적인 구조를 이룬다.
![](https://i.imgur.com/tWYHJ6g.png)



## 5.1 설계 사상

### 희소 성질과 조밀성질
시스템이 _희소성질_ 을 가지면 극히 일부 구성요소 사이에서만 상호작용이 일어나고, _조밀성질_ 을 가지면 대부분의 구성요소 사이에 상호 작용이 일어난다.

생체신경망은 연관성있는 뉴런끼리 연결된 희소연결구조로 이루어진다. 인공신경망도 완전 연결구조보다 상관성있는 출력끼리 연결된 희소연결구조를 갖는 편이 성능이나 컴퓨팅 자원의 효율성 측면에서 바람직함

반대로 하드웨어의 연산 효율로 따지면 조밀성질을 갖는 구조가 더 효율적이다.

인셉션 모듈은 성능가 컴퓨팅 자원의 효율성을 높이기 위한 희소연결을 가지면서 동시에 하드웨어 효율연산을 위해 조밀 연산을 하도록 설계되었다.

### 역할의 분리
인셉션 모듈은 역할을 다양하게 구성해두고 상황에 따라 필요한 역할을 선택하도록 설계되었다. 

![](https://i.imgur.com/s4PDKFw.png)



인셉션 모듈은 4가지 역할로 구성된다. 각 역할은 1x1 컨볼루션, 3x3컨볼루션, 5x5컨볼루션, 맥스풀링이다.

1x1컨볼루션은 채널 특징을 인식하며, 3x3과 5x5 컨볼루션은 서로 다른 크기의 수용영역에서 공간 특징과 채널 특징을 통합적으로 인식한다. 맥스풀링은 가장 두드러진 특징을 인식한다.

### 희소연결
인셉션 모듈이 어느 계층을 구성하는지에 따라 필요한 역할이 달라지며 필요없는 역할은 연결할 필요가 없으므로 연결이 희소해진다.

### 조밀연산
하드웨어 연산 효율을 높이기 위해 모든 역할의 결과를 합쳐서 조밀연산을 한다.

## 5.2 인셉션 모듈
### 기본 인셉션 모듈
기본 인셉션 모듈은 좋은 설계 사상을 가졌지만 한가지 문제가 존재함


기본 인셉션 모듈은 데이터의 채널 수가 과도하게 증가하는 문제가 있음

구조적으로 맥스풀링은 입력과 출력의 채널수가 같으므로 다른 컨볼루션 결과를 합치면 채널 수가 증가할 수 밖에 없다.

채널 수가 증가하면 그에 비례하여 연산량도 증가한다.

### 개선된 인셉션 모듈
![[assets/스크린샷 2024-05-28 22.10.27.png]]

기본 인셉션 모듈의 문제를 해결하기 위해 개선된 인셉션 모듈은 _병목계층_ 을 두어 채널 수와 연산량을 대폭 줄였다. 

병목 계층은 1x1컨볼루션으로 채널의 차원을 축소하는 계층이다.

병목 계층을 갖는 개선된 인셉션 모듈은 위 그림과 같음

컨볼루션은 연산 전 병목계층을 두어 채널 수를 줄이고, 맥스풀링은 연산 후 병목 계층을 두어 차원을 줄인다.

## 5.3 모델 구조
구글넷 구조는 _스템(stem), 몸체(body), 최종 분류기(final classifier), 보조 분류기(auxiliary classifier)_ 로 나뉘며 22계층으로 구성된다.

인셉션 모듈은 2계층으로 계산하면 9개 인셉션 모듈은 18계층이 되고, 컨볼루션 3계층과 FC1계층을 더하면 총 22계층이 된다. 22계층에는 파라미터를 갖는 계층만 포함되고  풀링 계층은 제외된다.

> - 스템 : 신경망의 도입부, 컨볼루션과 풀링으로 구성됨, 인셉션 모듈의 효과가 없어서 일반적인 구조 형성
> - 몸체 : 인셉션 모듈을 9개 쌓음, 1, 3, 8번째 인셉션 모듈 전에 맥스 풀링을 두어 액티베이션 맵의 크기를 줄임
> - 최종 분류기 : 완전연결계층 대신 평균 풀링을 사용해서 파라미터수를 줄임(AvgPool - FC - Softmax)
> - 보조 분류기 : 2개의 보조 분류기를 사용, _하위 계층에 그레디언트를 원활히 공급하는 역할_ 과 모델 정규화를 역할을 한다. 다만 훈련 용도로만 사용하고, 테스트할 때는 사용하지 않음(AvgPool - 1 X 1 conv - FC - FC - softmax)

![[스크린샷 2024-05-29 14.25.00.png]]

# 6. ResNet
> 레즈넷은 구글넷과 마찬가지로 네트워크 모듈을 여러 계층으로 쌓는 _Network in Network(NIN)_ 구조로 설계 되었다.

레즈넷은 152계층의 매우 깊은 신경망이다. (구글넷은 22계층인걸 감안하면 매우 놀라운 깊이)

하지만 깊이가 매우 길다면, 어떻게 학습을 진행했을까??

그거에 대한 답은 레즈넷은 _잔차연결(residual connection)_ 을 가지는 구조 때문이다.
(레즈넷 Cifar-10 모델은 성능 손실없이 1202계층까지 구성된다...)

다음 그림은 레즈 블럭의 도식화이다.
![[assets/Pasted image 20240529143108.png]]

## 6.1 설계 사상
학습을 통해 좋은 성능을 갖게 된 20계층 신경망이 있다고 가정할 때,

이 모델에 계층을 추가하여 56계층만들면 성능이 좋아질까?? 

실험 결과 훈련 결과와 테스트 오류 둘다 증가하는 현상이 나타났다. ![[assets/스크린샷 2024-05-29 14.33.21.png]][신경망이 깊어지면서 그래디언트 소실이 발생했다고 주장함]

모델을 깊게 하더라도 최소한 얕은 모델 이상의 성능 이상이 나오게 할 수 없을까 라는 생각으로부터 시작한다.

이를 구현하는 방법은 얕은 모델을 낮은 계층에 복사하고, 그 위에 _항등 매핑(identity mapping)_ 계층을 쌓는다면 최소한 얕은 모델만큼은 성능을 보장할 수 있다.

항등 매핑 계층은 입력을 그대로 출력하고 그래디언트도 그대로 전달하기 때문에 성능을 저하시키지 않는다.

여기서 더 나아가 한 단계 나아가 학습이 필요하면 입/출력 매핑을 학습하고, 학습이 필요 없으면 입력을 그대로 통과하게한다.

## 6.2 레즈 블럭(residual Block)
이러한 생각으로 만들어진것이 레즈블록이다. 

레즈블록은 컨볼루션 계층이 포함된 학습경로와 항등함수로 정의된 항등매핑 경로로 구성된다.

입력데이터는 두 경로를 따라 실행되며 실행 결과는 더해져 출력데이터가 된다.

레즈블록의 항등매핑을 *잔차 연결* 이라 하며, 잔차연결은 학습이 필요없을 때 입력을 그대로 전달하는 역할과 동시에 그래디언트가 잘 흐를 수 있도록 하는 지름길 역할도 한다.
 ![[assets/Pasted image 20240529143108.png]]
### 레즈블럭의 학습내용
그러면 레즈블럭은 무엇을 학습할까?
![[assets/스크린샷 2024-05-29 14.41.19.png]]

일반적인 컨볼루션 계층구조에서는 x를 입력하면 $H(x)$를 출력하는 매핑을 학습한다.

반면에 레즈블록은 x를 입력하면 항등매핑경로에서는 x를 출력하고, 학습경로에서는 $F(x)$를 출력하므로, 레즈블록은 두 경로의 출력을 더한 $H(x) = F(x) + x$를 출력한다. 

따라서 학습 경로에서는 모듈의 입력과 출력의 차이인 잔차 $F(x) = H(x) - x$를 학습한다.

학습경로에서 잔차를 학습하기 때문에 학습 경로를 잔차경로라 부른다.

### 레즈넷의 앙상블 효과
레즈 블록에는 두가지 경로가 있으므로 블록을 깊게 쌓을수록 입력에서 출력까지 갈 수 있는 경로가 다양ㅇ해진다. (N개의 블록이 존재하면 경로는 $2^n$)

모델을 실행할 때마다 매번 입력데이터가 다른 경로로 갈 수 있으므로 여러 모델을 실행하는 것과 같은 앙상블 효과가 있다.
![[assets/Pasted image 20240529152549.png]]

## 6.3 모델 구조
레즈넷 구조는 _스템, 몸체, 분류기_ 로 나뉘며 18계층부터 34계층, 50계층, 101계층, 152계층까지 5가지 모델로 구성된다.
> 스템 : 신경망 도입부, $7\times7$컨볼루션 계층으로 구성
> 몸체  : 레즈 블록으로 쌓은 부분, 모델 구성에 따라 쌓는 규칙이 달라짐
> 분류기 : FC계층을 제거하고, 전역 평균 풀링을 사용해서 파라미터 수를 대폭 줄임, FC계층은 클래스 출력을 위한 FC1000계층만 존재

### 병목 계층이 추가된 레즈 블록
50계층 이상인 경우 계산효율을 위해 병목계층을 추가한 레즈블록을 사용한다. 

### 전역 평균 풀링
전역 평균 풀링은 채널별로 평균을 구해서 1차원 벡터로 차원을 축소하는 방법이다.

따라서 축소된 1차원 벡터의 크기는 채널수와 같다.

## 6.4 훈련방식
- 배치 정규화(컨볼루션 연산 뒤 항상 배치 정규화)
- 정규화 기법 :$L_2$와 데이터 확장 
- ReLU, He 초기화
- SGD 모멘텀
- 배치 크기 : 256
- 학습률 : 적응형 학습률
- 


# 컨볼루션 신경망 비교
![[스크린샷 2024-05-29 15.33.17.png]]

모델별 정확도, 연산량 모델 크기 비교

y축이 정확도, x축이 연산량 원의 지름이 모델 크기


# 7. 다양한 모델 등장
구글넷과 레즈넷이 등장하면서 인셉션 모듈의 역할별 _분리 - 변환 - 통합_ 전략과 레즈블록의 잔차학습을 위한 _잔차연결_ , 네트워크 모듈을 쌓아서 만드는 _네트워크 속 네트워크(NIN)_, 파라미터와 연산량 감소를 위한 _병목계층과 FC계층_ 제거등의 설계 방식은 신경망 설계에 중요한 지침이 되었다.

## 7.1 레즈넷 개선 모델
### 레즈블록의 연산순서와 항등 매핑 개선
레즈블록의 연산 순서를 살펴보면 학습 경로에서는 `Conv - BN - ReLU - Conv - BN`이 실생되고, 두 경로가 더해지면서 `Sum - ReLU`가 실행된다. 레즈 블록에서 ReLU는 2번 실행되는데 첫번째는 학습 경로에서 실행되고,, 두번째는 두 경로가 더해진 이후에 실행된다.

레즈블럭의 이러한 연산은 전통적인 뉴런의 실행 순서인 _가중 합산 후 활성화_ 순서로 설계되었다.

하지만 실험을 해본 결과(컨볼루션, 배치 정규화, ReLU를 다양한 순서로 조합해서 실험)...

배치정규화, ReLU를 실행한 후 컨볼루션 연산을 하는 것이 더 좋은 성능을 얻을 수 있다는 의미이다.

즉 `활성화 후 가중 합산`순서를 따르기 때문에 전통적인 뉴런의 실행순서가 반드시 최적의 성능을 보장하는 것은 아님을 시사한다.

또한 항등 매핑 경로상에 정보 변경이 발생하면 정확히 항등 매핑이 되지 않는다. 그래서 두번 째 ReLU의 위치를 학습경로로 옮겨 `BN - ReLU - conv - BN - RELU - Conv` 다음 항등 매핑을 진행한다.

### 와이드 레즈넷
와이드 레즈넷은 신경망을 깊게만 설계하면 최적화가 어렵고 성능 향상에 한계가 존재하므로, 신경망의 너비를 늘리는 구조를 가지자는 생각으로 만들어진 모델이다.

레즈블록이 병렬처리 될 수 있도록 넓은 레즈 블록으로 확장해서 계산 효율을 높였다.

> 여기서 넓다는 의미는 레즈블록이 컨볼루션 필터를 F개 사용할 때 k배 넓은 $F \times k$ 필터를 사용한다는 의미다.
> 필터 개수가 늘어나면 액티베이션 맵의 채널수도 k개 늘어나고, 뉴런수도 k배 늘어나므로 더 넓은 신경망이 된다.

### 레즈넥스트
레즈넥스트는 레즈 블록의 잔차 경로를 여러 개로 분리해서 병렬실행하는 모델이다.

인셉션 모듈과 같이 분리 - 변환 - 통합 전략을 적용함과 동시에 레즈넷처럼 동일한 블록을 반복함으로써 하이퍼파라미터의 수를 줄이는 방식으로 넓은 신경망 구조를 갖도록 설계되었다.

레즈넥스트에서 같은 변환을 몇 번 하는지 _기수_ 로 정의하고 신경망을 스케일링 할 때 깊이, 넓이보디 더 많은 영향을 미치는 제 3의 요소로 기수가 존재한다.

레즈넥스트의 연산은 사실 그룹 컨볼루션과 동일하다

### 깊이가 확률적으로 변하는 신경망
_깊이가 확률적으로 변하는 신경망_ 은 훈련하는 동안 네트워크를 짧게 만들어서 그래디어늩 손실을 줄여보자는 아이디어로 만들어졌다.

훈련할 때는 부분경로를 드롭아웃하고, 테스트할 때는 전체 경로를 사용한다. 드롭아웃된 계층은 항등 매핑 경로를 통해 데이터를 그대로 통과시킨다.

## 7.2 레즈넷을 넘어선 모델
### 프렉탈 넷
_프렉탈넷(FractalNet)_ 은 잔차 구조보다는 얕은 네트워크에서 깊은 네트워크로의 효율적인 전환이 성능에 더 중요하다는 설계사상으로 만들어진 모델이다. 

얕은 경로와 깊은 경로를 모두 갖는 구조를 가지며 훈련할 때 부분 경로를 드롭아웃하고 테스트할 때는 전체경로를 사용한다.

![](https://freopen.com/assets/img/FractalNet-overview.png)


### 댄스넷(DenseNet)
댄스넷은 댄스블록으로 구성된 모델이다.

댄스블록은 모든 계층이 이전의 모든 계층과 연결된 구조로 이루어진다.

모든 계층이 연결되면 하위 수준의 특징이 직접 전파되어 재사용될 수 있고, 그래디언트 소실 문제도 해결된다.

또한 연결을 합치는 방식도 레즈블록과 다른데, 레즈블록은 두 경로의 출력을 더하는 반면, 댄스블럭은 이전 계층의 출력을 채널 방향으로 합침(concatenate)으로써 정보를 원래대로 보존한다.
![rmyYb2E.png](https://i.imgur.com/rmyYb2E.png)

### MobileNet
모바일 및 임베디드 비전 어플리케이션을 위해 개발되었으며 Depthwise separable convolution을 사용하여 Deep Neural Network를 구축한 모델이다.

모바일넷은 Depthwise separable convolution을 사용하여 계산 및 모델의 파라미터 수를 대폭 줄였다.

