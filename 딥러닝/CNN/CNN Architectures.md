#deep_learning #CNN #Architecture 


# 1. LeNet - 5
> 최초의 컨볼루션 신경망
![[스크린샷 2024-05-27 02.33.09.png]]
## 1.1 모델구조
르넷-5는 `CONV - POOL - CONV - POOL - FC - FC - FC`로 구성된 7계층 모델이다.

![[Pasted image 20240527023538.png]]

컨볼루션 계층과 풀링 계층을 2번 씩 반복한 뒤 완전 연결 3계층으로 연결되는 구조다.

컨볼루션 계층과 풀링 계층은 생체 신경망의 시각 영역을, 완전연결계층은 연관영역을 모델링 했다.


# 2. AlexNet
`이미지넷(imageNet)` 은 약 1,400만 개의 이미지로 구성된 이미지 데이터 베이스로서 20000만여개의 카테고리를 포함한다.

그중 알렉스넷은 이미지넷을 활용한 객체인식오류를 압도적으로 낮추며 1위를 차지한 최초의 컨볼루션 신경망 모델이다.

## 2.1 모델 구조
알렉스 넷은 2개의 GPU에서 실행되는 병렬처리 구조로 설계되었다. 

~~당시 gpu로는 한개로 실행시킬 수 없어 병렬처리 구조로 설계하고 2개의 gpu에서 실행~~

알렉스 넷은 컨볼루션 필터를 두 그룹으로 나눈 뒤 그룹별로 GPU를 할당하여 처리하고, 중간 계층에서 정보를 교환하여 최종 결과를 한쪽 그룹으로 합친다.

### 병렬처리 방식
첫 번째 계층에 $277 \times 277 \times 3$ 입력 데이터가 들어오면 그룹별로 48개 컨볼루션 필터가 연산을 수행한다.

정보를 교환하기 위해 Conv3과 Conv5, FC6, FC7 계층에서 그룹 간 출력을 교환하여 출력 계층인 FC8에서 전체 결과를 합친다.

![[스크린샷 2024-05-27 02.43.31.png]]

이미넷으로 알렉스 넷을 훈련했을 때 5~6일 정도 소요되었고, 이들이 사용한 그룹을 나눠 처리하는 방식은 그룹 컨볼루션이란 이름으로 레즈넥스트 모델에 도입되어 그룹 내에서 채널 간의 상관관계 구조를 학습하는 용도로 활용되고 있다.

### 모델구조
알렉스넷의 병렬처리 구조를 하나의 구조로 합치면 다음과 같다.

알렉스 넷은 `conv-conv-conv-conv-conv-fc-fc-fc`로 구성된 8계층 모델이다.

컨볼루션 5계층이 완전연결 3계층과 연결된 구조이다. (이때 풀링은 컨볼루션 계층에 포함된다.)

알렉스넷의 첫 번째 계층은 `11x11, 4` 컨볼루션 연산을 진행한다. 

상대적으로 큰 컨볼루션 피러와 스트라이드를 사용하므로 학습이 잘 안되는 문제가 존재하며, 나머지 컨볼루션 계층은 `3x3, 1` 컨볼루션 연산을 한다.

CONV1, CONV2, CONV5에서는 `3x3, 2` 로 맥스 풀링하며 한 픽셀씩 겹치도록 풀링한다.

CONV1과 CONV2에서는 지역응답정규화라고 불리는 _LRN(local response normalization)_ 방식으로 출력을 정규화한다.

LRN정규화는 픽셀별로 이웃 채널의 픽셀을 이용하여 정규화하는 방식으로 지금은 잘 사용하지 않는다.

ReLU의 출력이 무한히 커질 수 있으므로 이를 막기 위한 정규화로 도입되었다. 227x227x3 입력이 들어왔을 때, 첫 번째 계층은 컨볼루션 맥스풀링 정규화 순서로 실행하며, 드랍아웃은 FC6, FC7계층에만 적용되어 있다.

### 모델 파라미터 수
알렉스 넷의 파라미터 수는 6천200백만 개에 달한다.

알렉스넷의 파라미터는 FC계층에 집중되어있는데, 초기 컨볼루션 신경망 모델들은 생체 신경망의 영역의 연관영역을 모델링하기 위해 FC계층을 포함하지만, 그 결과 파라미터가 과도하게 쓰이는 문제가 존재한다. 

구글넷 이후 나온 모델들은 파라미터를 줄이기 위해 출력 계층을 제외하고 모든 계층을 컨볼루션계층으로 구성한다.

## 2.2 훈련방식
- GPU를 활용함으로써 압도적인 성능 향상
- LRN, 드롭아웃(p = 0.5), $L_2$정규화, 데이터 증강 등 정규화 기법사용
- 앙상블 (모델 7개)
- SGD 모멘텀
- 배치크기 128
- 학습률 : $1e-2$

# 3. 제프에프넷(ZFNet)
![[스크린샷 2024-05-28 20.27.52.png]]

제프에프넷은 모델 시각화 방식으로 알렉스넷의 문제점을 분석하고 개선했다.

## 3.1 모델 구조
기본 구조는 알렉스넷과 동일하지만, 다음과 같이 일부 개선되었다.

- Conv1의 컨볼루션을 11x11,4에서 7x7,2 로 바꿨다.
- conv3,conv4,conv5의 필터 개수를 384,384,256에서 512,1024,512로 조정했다.
- 모델을 학습하기 위해 그룹을 하나로 합침

Conv1 컨볼루션 연산을 바꾼 이유는, 알렉스넷의 시각화 결과 첫번째 계층이 잘 학습되지 않는다는 사실을 발견했기 때문이다.

지나치게 크게 설계된 수용영역 때문이었는데, 컨볼루션 필터의 크기와 스트라이드를 조정한 뒤 정상적으로 학습이 되었고, 이를 시각화를 통해 확인했다.

## 3.2 모델 시각화 방식
시각화를 통해 다음과 같은 사실을 입증함
> - 컨볼루션 신경망의 계층이 높아질수록 수용영역이 넓어지고, 지역적 특징에서 전역적 특징으로 학습내용이 변경된다.
> - 낮은 계층에서 먼저 학습되기 시작해서 점점 높은 계층으로 학습이 진행된다.
> - 입력에 작은 변화가 있어도 동일한 결과를 출력하는 _위치불변성_ 을 갖는다.
> - 특징을 포착할 때 모양은 물론이고 위치까지 가늠한다.

### 디컨볼루션 네트워크
시각화한 방법으로는 컨볼루션의 역연산으로 액티베이션 뱁을 픽셀공간에 투영하는 방식이다.

이를 위해 디컨볼루션 네트워크를 만들었는데, 다음 그림과정 계층에 액티베이션 맵을 시각화하려면, 짝을 이룰 디 컨볼루션 계층에 액티베이션 맵을 입력해서 입력 계층 방향으로 디컨볼루션을 수행한다.


# 4. VGG Net
> 작은 필터를 사용하는 대신 깊은 신경망을 만들자

## 4.1 설계 사상
VGG는 신경망이 깊어질수록 수용영역이 넓어지는원리를 이용하여, 필터를 작게 만들어서 파라미터 수를 줄이고 대신 신경망을 깊게 하여 수용영역을 충분히 설계했다.

### 큰 컨볼루션 필터 VS. 작은 컨볼루션 필터
뉴런의 수용영역은 컨볼루션 필터의 크기, 스트라이드, 계층에 따라 정해진다. (예를 들어 수용영역이 5인 뉴런을 만들려면 한 계층에 크기가 5인 컨볼루션 필터를 사용해도 되지만, 두 계층에 각각 3인 컨볼루션 필터를 사용할 수도 있다)

같은 수용영역을 나타내는 두 방식 중 작은 필터를 사용해서 여러 계층으로 쌓는 방식이 파라미터 수를 줄이는 방식이라고 말할 수 있다.

## 4.2 모델 구조
VGG는 11계층부터 13계층, 16게층, 19계층까지 총 6가지 종류의 모델로 구성된다.

### 다양한 계층으로 구성된 VGG
그 중 16계층을 제일 많이 사용하며, 짧게 VGG16이라 부른다. 19계층을 사용한 경우는 파라미터수는 많지만 성능차가 크지않아 많이 쓰이지 않는다.

### VGG16 모델 구조
VGG16은 계층별로 특징을 추출해서 사용할 때가 많으므로 계층마다 이름이 있다.

또한 출력 크기에 따라 컨볼루션 계층을 그룹으로 묶어서 부른다. 그래서 5개의 그룹 CONV1,CONV2,CONV3,CONV4,CONV5이 완전 연결 계층으로 연결되는 구조를 이룬다.
![[스크린샷 2024-05-28 20.58.22.png]]


### FC7 계층의 활용
이미지의 특징을 추출할 때 많이 사용한다. 예를 들어 스타일 변환을 할 때 VGG를 사용해서 일부 계층의 특징으로 스타일을 생성한다. 

특히 FC7의 특징은 이미지를 설명하는 콘텍스트 벡터로 쓰이곤 한다. FC7이 출력 직전의 계층이므로 FC7에서 이미지 표현이 가장 추상화된 상태이기 때문이다.

### 모델 파라미터 수
초기계층은 메모리 사용량이 많고, 후반 계층은 파라미터가 집중되어있다.
- 메모리 사용량 96m
- 파라미터 수 : 138M

# 5. 구글넷
구글넷은 전형적인 컨볼루션 신경망의 구조를 탈피하여 네트워크 모듈을 쌓는 방식의 네트워크 속 네트워크 구조로 설계되었다.

전체 파라미터 수는 5m으로 알렉스넷보다 12배 적으면서도 깊은 신경망을 실현할 수 있는 효율적인 구조를 이룬다.
![[스크린샷 2024-05-28 21.54.09.png]]


## 5.1 설계 사상

### 희소 성질과 조밀성질
시스템이 _희소성질_ 을 가지면 극히 일부 구성요소 사이에서만 상호작용이 일어나고, _조밀성질_ 을 가지면 대부분의 구성요소 사이에 상호 작용이 일어난다.

생체신경망은 연관성있는 뉴런끼리 연결된 희소연결구조로 이루어진다. 인공신경망도 완전 연결구조보다 상관성있는 출력끼리 연결된 희소연결구조를 갖는 편이 성능이나 컴퓨팅 자원의 효율성 측면에서 바람직함



인셉션 모둘은 성능