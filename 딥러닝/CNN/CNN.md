#책 #deep_learning #CNN 
*0513일 딥러닝(오민식교수님)수업과 딥러닝 교과서를 참고함*

순방향신경망은 데이터에 특별한 구조를 가정하지 않으므로 이미지와 같은 공간 데이터를 처리 한다면 공간적인 특성을 무시하게된다. 또한 고차원 공간을 표현하려면 데이터는 커질 수 밖에 없고, 모델도 같이 커지기 때문에 모델의 파라미터 수가 급격히 증가하는 문제가 있다. 이와 같은 순방향 신경망의 한계를 극복하기 위해 네오코그니트론이 제안되었고, 이후 CNN이 나오면서 지금까지 컴퓨터 비전 분야의 발전을 견인해오고 있다. 

이번챕터는 CNN이 이미지 처리를 위해 생체신경망의 어떤 점을 모방했고 어떤방식으로 데이터를 처리하는지,   그리고 모델이 갖는 성질이 무엇인지 확인하면서, 표준 Convolution 연산의 한계를 극복하고자 제안된  다양한 방법들을 살펴본다

# 1. 시각패턴인식을 위한 신경망 모델
MNIST 기준으로 순방향 신경망은 2차원 이미지를 1차원 벡터로 변환해서 모델을 입력해야 하므로 숫자 인식이 어려움 -> 공간데이터를 1차원으로 변환하는 순간 형상 정보가 분산되기 때문에 정확한 패턴을 인식하기 어려움

고차원 데이터는 차원 별로 크기가 조금만 커져도 전체데이터 크기가 기하급수적으로 증가하기에 파라미터 수도 그만큼 증가하게 된다. 그렇기에 순방향은 이미지 처리에 비 효율적이다.

## 1.1 생체 시각 시스템을 모방한 인공신경망
#### **생체 신경망과 계층적 시각정보처리**
- **뉴런은 아주 좁은 영역의 자극에 반응함** : 뉴런이 자극을 받아들이는 영역을 수용영역이라하는데, 뉴런은 좁은 영역의 자극에 반응하는 국소적인 수용영역을 갖는다.
- **뉴런마다 다른 모양의 특징을 인식하도록 뉴런의 역할이 나뉜다.** : 고양이에게 여러 모양의 형체를 보여줄 때 모양에 따라 서로 다른 뉴런이 반응함
- **뉴런은 계층 정보를 이루며 시각정보를 계층적으로 처리한다.** : 상위 뉴런은 하위 뉴런으로부터 시각정보를 받아서 특징을 인식하는 만큼 더 넓은 수용영역을 가지며, 계층이 높아질수록 수용영역이 점점 넓어져서 최종적으로 전체 시각 영역을 형성함 계층 구조의 가장 하위에 있는 뉴런으로서 단순세포는 선분을 탐지, 복합세포는 단순세포들로부터 시각정보를 받는 뉴런으로 선분의 움직임에 대해 반응하는 위치불변성을 갖는다. 초복합세포는 복합 세포의 상위 뉴런으로서 두 개의 선분이 이루는 모서리나 곡선 또는 선분의 끝을 탐지


# 2. 콘벌루션 신경망의 구조
콘볼루션 계층은 콘벌루션 연산을 통해 이미지의 다양한 특징을 학습하며, 서브 샘플링 계층은 풀링 연산을 통해 이미지의 크기를 줄여서 특징의 작은 이동에 대한 위치 불변성을 갖도록 한다. 콘볼루션 신경망에서 수용영역은 뉴런이 데이터를 전달받은 입력 이미지의 영역이다. 콘볼루션 연산과 서브샘플링 연산이 더 많이 실행될수록 뉴런의 수용영역은 점점 더 넓어지면서 작은 영역의 단순한 특징부터 넓은 영역의 복잡한 특징까지 계층적으로 인식한다.

## 2.1 콘볼루션 연산

convolution이란 두 함수를 곱해서 적분하는 연산, 함수 *f*에  다른 함수 *g*를 적용하여 새로운 함수 *f^*  를  만들 때 사용함  

### 콘볼루션 연산
두 연속 함수 *f(t)* 와 *g(t)* 가 있다고 가정

## 2.2 이미지 콘볼루션 연산
이미지에 대한 콘볼루션은 이미지의 특징을 추출하거나 이미지를 변환할 때 사용

### 경계선 검출 이미지 콘볼루션 연산 정의
이미지에 대한 콘볼루션 연산을 식으로 정의

2차원 이미지가 $I$ , 콘볼루션 필터가 $K$라면 이미지에 대한 콘볼루션 연산 $(I * K)(i, j)$는 다음과 같이 정의됨
함수의 인자 $(i,j)$는 픽셀 인덱스. 이미진는 입력 함수가 되고, 콘볼루션 필터는 가중치함수가 되어 픽셀단위로 가중합산을 함

$$(I *K)(i,j) = \sum_m\sum_nI(m,n)K(i-m,j-n)$$

이미지 처리할 때는 필터를 반전시키지 않기 때문에 콘볼루션 연산이 아닌 교차상관연산을 함
필터가 대칭적인 경우 두 연산은 동일함. 이미지에 대한 교차상관 연산은 다음과 같이 정의함
$$(I *K)(i,j) = \sum_m\sum_nI(m,n)K(i+m,j+n)$$
따라서 콘볼루션 신경망도 교차상관 연산을 하지만 콘볼루션 연산을 한다고 표현

CNN은 둘 중 어떤 연산을 사용하더라도 그에 맞춰서 필터가 학습되는 만큼, 결과에는 차이가 없음

다만 필터를 반전하지 않는 편이 간단하므로 교차상관을 사용함

### 이미지 콘볼루션 연산과정

	7x7 이미지와 3x3 필터가 있다고 가정
콘볼루션 연산의 첫번째 가중합산은 다음과 같이 계산함. 이미지와 콘볼루션 필터를 왼쪽 위 모서리에 맞춰서 픽셀 단위로 가중 함삽을 하면 새로운 이미지의 첫 번째 픽셀 $y_{11}$이 생성됨
$$
\begin{align*}
y_{11} &= w_{11}x_{11} + w_{12}x_{12} + w_{13}x_{13} \\
&\quad + w_{14}x_{14} + w_{15}x_{15} + w_{16}x_{16} \\
&\quad + w_{17}x_{17} + w_{18}x_{18} + w_{19}x_{19}
\end{align*}
$$


### convolution 필터의 슬라이딩 순서
이미지에서 콘볼루션 필터를 슬라이딩 할때는 2차원 공간에서 슬라이딩 하므로 가로방향과 세로 방향의 순서를 정해야함

보통 가로 한줄 슬라이딩 후 세로 방향으로  한칸 아래로 이동하는 순서로 진행됨


#### 이미지 컨볼루션 필터 설계 예시
각 task에 따라 사용하는 필터가 다름



## 2.3 컨볼루션 신경망의 컨볼루션 연산
컨볼루션 신경망은 이미지의 특징을 추출하기 위해 컨볼루션 필터(*파라미터*)를 학습하며, 특징의 추상화 수준에 따라 컨볼루션 연산을 여러 단계로 계층화해서 실행한다

신경망 모델에서 이미지 컨볼루션 연산을 어떤 방식으로 활용하는지 살펴보면 다음과 같음
	 - 데이터에 내포된 다양한 특징을 추출하도록 특징에 따라 별도의 컨볼루션 필터를 둔다. 컨볼루션 필터별로 서로다른 특징을 추출하므로, 데이터의 특징이 다양하다면 그만큼 컨볼루션 필터개수를 늘려줘야한다. 하짐나 이미지가 몇 개의 특징을 내포하고 있는지 미리 알기는 어렵기에 검증과정을 통해서 필터 개수를 조정해야한다. 
	 - 컨볼루션 필터의 크기와 개수는 계층별로 특징의 추상화 수준에 따라 다르게 설계해야한다. 추상화 수준이 높아질수록 특징이 세분화 되므로 더 많은 종류의 필터가 필요함
	 - 컨볼루션 필터의 값은 데이터의 특징을 잘 추출하도록 학습을 통해 정한다. 즉 미리 설계된 컨볼루션 필터를 사용하지 않고, 이미지의 특징에 따라 최적의 값으로 정의되도록 학습과정에서 결정함

### 입력데이터의 형태
컨볼루션 신경망의 입력데이터가 이미지라고 가정, 이미지는 눈으로 볼때는 2차원이지만, 색깔별 빛의 강도를 나타내는 채널(channel)이 존재하기 때문에 3차원으로 표현(RGB 채널, 투명도로 하면 RGBA, 흑백이미지는 한개의 채널)

따라서 컨볼루션 신경망의 입력 데이터는 *[Width] X [height] X [Depth]* 로 표현되는 3차원 텐서로 나타낼 수 있음
![[스크린샷 2024-05-26 21.05.35.png]]



[Width] x [Height] 는 공간특징을 표현, [Depth]는 채널 특징을 표현한다. (흑백은 뎁스1, 컬러는 뎁스3, 투명도포함 뎁스 4)

### 컨볼루션 필터의 형태 
컨볼루션 필터도 3차원 텐서로 정의됨. 표준 컨볼루션 연산은 채널 방향으로 슬라이딩하지 않으므로, 컨볼루션 필터의 Depth는 입력데이터의 Depth와 동일해야한다. 

![[스크린샷 2024-05-26 21.14.22.png]]

### 컨볼루션 필터의 크기와 개수
뉴런의 수용영역은 컨볼루션 필터의 크기에 따라 달라진다. 
## 질문 -> 20분까지
인풋에 대해 커널을 통해 결과를 만들어내는게 컨볼루션, 커널이 필터, 결과를 통해 인풋의 여러 미쳐를 뽑아내고, 뽑아낸 피쳐를 이용해 모델을 학습?

-> 뽑아낸 피처를 통

max fooling을 사용하는 이유?
avg나 max냐 정답은 없음 -> 하지만 max를 더 많이 쓰는데 noise robustic함


## Architecture of CNN
- cnn진행 후 fc진행

## Fully Connected layer
- 좀 오버헤드임
- classification -> softmax

## 초창기 cnn기반 classification : Lenet-5
cnn -> cnn -> fc -> fc -> classification

# Variants of the Convolution
## Receptive Field
