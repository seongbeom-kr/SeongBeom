전통적인 특성중요도를 확인했을 때
좋아요수, 상품의 전체 리뷰수, 상품의 전체 평점, 리뷰어의 BMI등 다양한 지표들이 중요하다고 나옵니다.

이제 LIME을 사용하여 유용한 리뷰에 대해 분석했을 때 다음과 같은결과가 나옵니다.

total_rating, 좋아요수, 
'rondom_forest'
param_grid = {

'n_estimators': [ 200, 500], # 트리의 개수

'max_depth': [10, 20, 30, None], # 트리의 최대 깊이

'min_samples_split': [2, 5, 10], # 노드를 분할하기 위한 최소 샘플 수

'min_samples_leaf': [1, 2, 4], # 리프 노드에 있어야 하는 최소 샘플 수

'max_features': ['sqrt', 'log2', None, 0.5], # 각 노드에서 고려할 최대 피처 수

'bootstrap': [True]

}

'XGBoost': {

'model': XGBClassifier(random_state=42, use_label_encoder=False),

'params': {

'n_estimators': [ 100,300,500],

'learning_rate': [0.01, 0.1, 0.2],

'subsample': [0.8, 1.0],

'colsample_bytree': [0.8, 1.0]

}

},

'LightGBM': {

'model': LGBMClassifier(random_state=42),

'params': {

'n_estimators': [ 100, 300,500],

'learning_rate': [0.01],

'num_leaves': [31, 50, 100],

'boosting_type': ['gbdt', 'dart'],

'feature_fraction': [0.8, 1.0]

}

},

'CatBoost': {

'model': CatBoostClassifier(random_state=42, verbose=0),

'params': {

'iterations': [ 100, 300,500],

'learning_rate': [0.01],

'depth': [4, 6, 10]

}

}

}
rondom 겨로가
precision recall f1-score support 0 0.98 0.96 0.97 14864 1 0.96 0.98 0.97 14856 accuracy 0.97 29720 macro avg 0.97 0.97 0.97 29720 weighted avg 0.97 0.97 0.97 29720

XGBoost 결과
precision recall f1-score support 0 0.98 0.94 0.96 14864 1 0.94 0.98 0.96 14856 accuracy 0.96 29720 macro avg 0.96 0.96 0.96 29720 weighted avg 0.96 0.96 0.96 29720

lightgbm결과
precision recall f1-score support 0 0.98 0.94 0.96 14864 1 0.94 0.98 0.96 14856 accuracy 0.96 29720 macro avg 0.96 0.96 0.96 29720 weighted avg 0.96 0.96 0.96 29720

catboost결과
precision recall f1-score support 0 0.98 0.92 0.95 14864 1 0.93 0.98 0.96 14856 accuracy 0.95 29720 macro avg 0.96 0.95 0.95 29720 weighted avg 0.96 0.95 0.95 29720