# 손실함수란?
![](https://i.imgur.com/JRJXMss.png)

오차 : 예측값과 실제값의 차이
비용함수 : 모든 오차를 최소화하기 위해 정의되는 함수

![](https://i.imgur.com/n5Hif8I.png)
$y = \alpha x + \beta$ 라고 가정할 때 우리는 오차를 최대한 줄이는 알파를 찾는게 목적임

이 알파를 찾기 위해서 많은 손실 함수를 정의하고 사용함

SSE, CEE ... Task와 데이터에 따라 손실함수를 정의하면 됨




확률적 경사하강법이란 손실 함수의 곡면에서 **'경사가 가장 가파른 곳으로 내려가다 보면 언젠가 가장 낮은 지점에 도달한다.'** 는 가정으로 만들어 짐

## 고정된 학습률
학습률 : 최적화 할 때 한 걸음의 폭을 결정하는 스텝 크기를 말하며 학습 속도를 결정한다. 

확률적 경사하강법은 지정된 학습률을 사용하는 알고리즘이므로 경험적으로 학습률을 결정할 수 밖에 없음

### 학습률을 조정하지 않으면 생기는 일
- 매우 비효율적임
- 높으면 최적해로 수렴하지 못하거나 손실이 커지는 방향으로 점점 발산할 수 있음
- 낮으면 속도가 느림

![](https://i.imgur.com/1grZdTO.png)

일반적인 경우 큰 학습률을 사용해 최대한 빠르게 내려가고, 어느정도 내려가면 작은 폭으로 천천히 이동해서 최적해에 접근하는 법을 사용 -> 스케쥴러 사용

## 경사하강법을 통한 최적화 방법은 가장 좋은 방법은 아님
비볼록 함수에도 이야기가 달라짐
![](https://i.imgur.com/h9DHxcu.png)

어느 점에서 시작하느냐에 따라서도 좀 달라짐

saddle point 문제도 있음
![](https://i.imgur.com/wu2Hveg.png)
